# CDPR Dataset Generator

This repository provides a **synthetic dataset generation pipeline** for the Cable-Driven Parallel Robot (CDPR) simulation in MuJoCo.  
It builds automatically annotated episodes compatible with **RLDS** / **Open-X Embodiment** style datasets, ready for use with **OpenVLA-OFT** or other visuomotor transformer models.

---

## ğŸ§© Repository Overview

```

cdpr_dataset/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ cdpr_dataset/
â”‚   â”œâ”€â”€ generate_cdpr_dataset.py      # main dataset builder
â”‚   â”œâ”€â”€ synthetic_tasks.py            # scripted trajectories (pick, push, etc.)
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ cdpr_scene_catalog.yaml   # scene/object definitions
â”‚   â”‚   â””â”€â”€ cdpr_synth/               # generated outputs
â”‚   â””â”€â”€ wrappers/                     # auto-generated scene wrappers
â””â”€â”€ scripts/
â”œâ”€â”€ make_dataset.sh               # CLI helper
â”œâ”€â”€ list_libero_objects.py        # lists available objects
â””â”€â”€ list_libero_scenes.py         # lists available scenes
```

---

## âš™ï¸ Installation

1. **Clone this repo** and ensure your main robot package is installed:
   ```bash
   git clone https://github.com/your-org/CDPR_Dataset.git
   cd CDPR_Dataset
   pip install -e .

2. Ensure your environment includes:

   * `openvla-oft` (for consistency with training)
   * your **installed CDPR simulator**:

     ```bash
     pip install -e /root/repo/VLA_CDPR/cdpr_mujoco
     ```

3. (Optional) If you want TFRecord export:

   ```bash
   pip install tensorflow rlds Pillow
   ```

---

## ğŸ§  Dataset Generation

Run the main generator:

```bash
python -m cdpr_dataset.generate_cdpr_dataset \
  --episodes_per_scene 2 \
  --tasks pick_and_hover push_left
```

Outputs are stored under:

```
cdpr_dataset/datasets/cdpr_synth/
â”œâ”€â”€ npz/                 # one .npz per episode (RGB frames + actions)
â”œâ”€â”€ videos/              # per-episode overview & end-effector videos
â”‚   â”œâ”€â”€ desk_pick_and_hover_00000/
â”‚   â”‚   â”œâ”€â”€ overview_video.mp4
â”‚   â”‚   â”œâ”€â”€ ee_camera_video.mp4
â”‚   â”‚   â””â”€â”€ trajectory_data.npz
â”‚   â””â”€â”€ desk_push_left_00001/ ...
â”œâ”€â”€ meta_dataset.json    # dataset metadata
â””â”€â”€ tfrecords/           # (optional) RLDS TFRecord shard
```

---

## ğŸ¥ Saving Per-Episode Videos

By default, `generate_cdpr_dataset.py` saves a video for each trajectory:

* `overview_video.mp4` â€” fixed external camera
* `ee_camera_video.mp4` â€” wrist-mounted camera
* `trajectory_data.npz` â€” saved end-effector poses, timestamps, and internal logs

If you experience frame contamination across episodes (rare), run with:

```bash
--reinit_each_episode
```

This reinitializes the MuJoCo simulator per episode to ensure clean recordings.

---

## ğŸ§¾ Scene and Object Catalogs

Scene/object definitions live in:

```
cdpr_dataset/datasets/cdpr_scene_catalog.yaml
```

Example:

```yaml
defaults:
  scene_z: -0.85
  ee_start: [0.0, 0.0, 0.25]
  table_z: 0.15
  object_dynamic: true
  settle_time: 1.0

scenes:
  - name: desk
    objects: [ketchup, orange_juice, milk]
```

Use the helper scripts to explore your available LIBERO assets:

```bash
python scripts/list_libero_objects.py
python scripts/list_libero_scenes.py
```

---

## ğŸ“¦ Dataset Structure

Each `.npz` episode contains a list of steps with keys:

| Key                                  | Description                               |
| ------------------------------------ | ----------------------------------------- |
| `observations/full_image`            | Overview camera RGB (HWC, uint8)          |
| `observations/wrist_image`           | Wrist-mounted camera RGB (HWC, uint8)     |
| `observations/state`                 | 8D normalized proprioceptive vector       |
| `language_instruction`               | task description (string)                 |
| `action/abs_7`                       | absolute Cartesian + yaw + gripper vector |
| `action/delta_7`                     | delta from previous step                  |
| `is_first`, `is_last`, `is_terminal` | step flags                                |
| `discount`, `reward`                 | scalar floats                             |

---

## ğŸ§® Tasks Implemented

Scripted trajectories in `synthetic_tasks.py`:

| Task             | Description                                    |
| ---------------- | ---------------------------------------------- |
| `pick_and_hover` | Move to object, close gripper, lift, and hover |
| `push_left`      | Push object along -X direction                 |
| `push_forward`   | Push object along +Y direction                 |

You can extend this by defining new motion scripts in `synthetic_tasks.py` and referencing them in `--tasks`.

---

## ğŸš€ Extending the Dataset

* Add new scenes or objects in `cdpr_scene_catalog.yaml`.
* Drop additional object folders under LIBERO assets or add external OBJ meshes via a converter (YCB, ShapeNet, etc.).
* Each added object is prefixed automatically in the wrapper XML to avoid asset-name collisions (`textured_vis`, etc.).

---

## ğŸ’¡ Tips

* Use `--strict_objects` to enforce that all listed objects exist (fail fast).
* Use `--reinit_each_episode` to guarantee isolated video clips.
* Videos are rendered through EGL; ensure your container or machine supports GPU EGL context.
* Generated wrappers are cached in `cdpr_dataset/wrappers/`.

---

## ğŸ§± Example End-to-End Command

```bash
python -m cdpr_dataset.generate_cdpr_dataset \
  --episodes_per_scene 3 \
  --tasks pick_and_hover push_left push_forward \
  --reinit_each_episode
```